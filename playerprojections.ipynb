{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Projections Notebook\n",
    "\n",
    "This Jupyter notebook is used for generating player projections in fantasy sports. It uses various Python libraries to scrape data, perform calculations, and visualize results.\n",
    "\n",
    "## Section 1: Importing Libraries\n",
    "\n",
    "The first section of the notebook is dedicated to importing the necessary Python libraries that will be used throughout the notebook:\n",
    "\n",
    "- `datetime`, `json`, `shutil`, `time`, and `pathlib.Path` are standard Python libraries used for handling date and time, JSON data, file operations, and file paths respectively.\n",
    "\n",
    "- `gspread` is used for interacting with Google Spreadsheets.\n",
    "\n",
    "- `matplotlib.pyplot` is used for creating plots and visualizations.\n",
    "\n",
    "- `numpy` and `pandas` are used for numerical computations and data manipulation.\n",
    "\n",
    "- `scipy.stats` is used for statistical computations.\n",
    "\n",
    "- `selenium` and its related imports are used for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gspread'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgspread\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gspread'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import gspread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preparation\n",
    "\n",
    "In this section, we will set CONSTANTS for desired column_order to be used later, as well as the number of players we want, URLs for All and Even strength stats, and the URL for our Fantrax league.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ORDER = [\n",
    "    \"Player\",\n",
    "    \"Team\",\n",
    "    \"Position\",\n",
    "    \"GP\",\n",
    "    \"D Points\",\n",
    "    \"Goals\",\n",
    "    \"Total Assists\",\n",
    "    \"Shots\",\n",
    "    \"Special Teams Points\",\n",
    "    \"Hits\",\n",
    "    \"Shots Blocked\",\n",
    "    \"Takeaways\",\n",
    "    \"Faceoffs Won\",\n",
    "    \"TOI\",\n",
    "]\n",
    "\n",
    "NUM_PLAYERS = 300\n",
    "URL_ALL_STRENGTHS, URL_EVEN_STRENGTH = (\n",
    "    \"https://www.naturalstattrick.com/playerteams.php?fromseason=20232024&thruseason=20232024&stype=2&sit=all&score=all&stdoi=std&rate=n&team=ALL&pos=S&loc=B&toi=0&gpfilt=none&fd=&td=&tgp=410&lines=single&draftteam=ALL\",\n",
    "    \"https://www.naturalstattrick.com/playerteams.php?fromseason=20232024&thruseason=20232024&stype=2&sit=ev&score=all&stdoi=std&rate=n&team=ALL&pos=S&loc=B&toi=0&gpfilt=none&fd=&td=&tgp=410&lines=single&draftteam=ALL\",\n",
    ")\n",
    "URL_FBL_FANTRAX = \"https://www.fantrax.com/fantasy/league/1papyorqllbhqzl7/players;statusOrTeamFilter=ALL;pageNumber=1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Data Preparation\n",
    "\n",
    "In this section, we will perform data preparation tasks such as loading data, cleaning data, and adding additional columns. \n",
    "\n",
    "Let's start by loading the data from the CSV files. The `load_data()` function is used to load the data from the specified file path. If the file exists and was modified within the last hour, it will load the data from the CSV file. Otherwise, it will scrape the data from the website and save it to the CSV file before loading it.\n",
    "\n",
    "Next, we will clean the data by adding a unique identifier for each player and performing any necessary data cleaning operations.\n",
    "\n",
    "Finally, we will add additional columns to the dataframe, such as \"D Points\" and \"Special Teams Points\", which will be used for further analysis.\n",
    "\n",
    "Let's execute the code block below to perform these data preparation tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(file_path):\n",
    "    # File path.. Path...\n",
    "    file = Path(file_path)\n",
    "    # 1 hour = 3600 seconds\n",
    "    hour = 3600\n",
    "    # Check if the file exists\n",
    "    if file.exists():\n",
    "        # Get the modification time of the CSV\n",
    "        modtime = file.stat().st_mtime\n",
    "        # Get the current time\n",
    "        current_time = time.time()\n",
    "        # If the file is less than an hour old, load it else scrape the data\n",
    "        dataframe = pd.read_csv(file_path, index_col=0) if current_time - modtime < hour else scrape_data(file_path)\n",
    "    # If the file doesn't exist, scrape the data\n",
    "    else:\n",
    "        dataframe = scrape_data(file_path)\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data\n",
    "def scrape_data(file_path):\n",
    "    # Set the URL based on the file path\n",
    "    if file_path == \"all_strengths.csv\":\n",
    "        url = URL_ALL_STRENGTHS\n",
    "    elif file_path == \"even_strength.csv\":\n",
    "        url = URL_EVEN_STRENGTH\n",
    "    # Scrape the data\n",
    "    dataframe = pd.read_html(url, index_col=0)[0] \n",
    "    # Save to csv\n",
    "    dataframe.to_csv(file_path)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.set_preference(\"browser.download.folderList\", 2) # custom location\n",
    "    options.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "    options.set_preference(\"browser.download.dir\", str(Path.cwd()))\n",
    "    options.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"text/csv\")\n",
    "    return webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, wait):\n",
    "    driver.get(\"https://www.fantrax.com/login\")\n",
    "    email = wait.until(ec.presence_of_element_located((By.CSS_SELECTOR, 'input[formcontrolname=\"email\"]')))\n",
    "    password = wait.until(ec.presence_of_element_located((By.CSS_SELECTOR, 'input[formcontrolname=\"password\"]')))\n",
    "    with Path(\"credentials.json\").open() as f:\n",
    "        credentials = json.load(f)\n",
    "    email.send_keys(credentials[\"username\"])\n",
    "    password.send_keys(credentials[\"password\"])\n",
    "    login_button = wait.until(ec.element_to_be_clickable((By.CSS_SELECTOR, 'button[type=\"submit\"]')))\n",
    "    login_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(driver, wait, file_path):\n",
    "    today = datetime.datetime.now(tz=datetime.UTC).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    url = f\"https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=1papyorqllbhqzl7&pageNumber=1&view=STATS&positionOrGroup=HOCKEY_SKATING&seasonOrProjection=SEASON_31h_YEAR_TO_DATE&timeframeTypeCode=YEAR_TO_DATE&transactionPeriod=15&miscDisplayType=1&sortType=SCORE&maxResultsPerPage=20&statusOrTeamFilter=ALL&scoringCategoryType=5&timeStartType=PERIOD_ONLY&schedulePageAdj=0&searchName=&datePlaying=ALL&startDate=2023-10-10&endDate={today}&teamId=0ph241vmllbhqzlf&\"\n",
    "    # Wait for the element with the class \"text--ellipsis\" to be present\n",
    "    wait.until(ec.presence_of_element_located((By.CSS_SELECTOR, \"h5.text--ellipsis\")))\n",
    "    driver.get(url)\n",
    "    default_filename = \"Fantrax-Players-Fantasy Beard League.csv\"\n",
    "    shutil.move(default_filename, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used to scrape data from Fantrax\n",
    "def scrape_fantrax(file_path):\n",
    "    file = Path(file_path)\n",
    "    # Check if the file exists and was modified today\n",
    "    if file.exists():\n",
    "        # Get the modification time of the CSV\n",
    "        modtime = datetime.datetime.fromtimestamp(file.stat().st_mtime, tz=datetime.UTC)\n",
    "        # Check if it was modified today\n",
    "        if modtime.date() == datetime.datetime.now(tz=datetime.UTC).date():\n",
    "            return pd.read_csv(file_path, index_col=0, nrows=1000)\n",
    "\n",
    "    # Set up the driver and set the wait time\n",
    "    driver = setup_driver()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    # Login to Fantrax\n",
    "    login(driver, wait)\n",
    "    # Download the data\n",
    "    download_data(driver, wait, file_path)\n",
    "    # Read the CSV into a dataframe\n",
    "    data = pd.read_csv(file_path, nrows=1000)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add D and STP column\n",
    "def add_d_and_stp(df_all, df_even):\n",
    "    # Add D and STP columns\n",
    "    df_all[\"D Points\"] = np.where(df_all[\"Position\"] == \"D\", df_all[\"Total Points\"], 0)\n",
    "    df_all[\"Special Teams Points\"] = df_all[\"Total Points\"] - df_even[\"Total Points\"]\n",
    "\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add things for cleaning data if needed\n",
    "def clean_data(dataframe):\n",
    "    # Create a unique ID for each player to avoid issues with same name players\n",
    "    dataframe[\"UID\"] = dataframe.groupby(\"Player\").cumcount()\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data\n",
    "def analyze_data(dataframe):\n",
    "    # Make a copy of the dataframe to avoid modifying the original data\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    # Start index at 1 for better readability (Python usually starts indexing at 0)\n",
    "    dataframe.index = dataframe.index + 1\n",
    "\n",
    "    # List of categories to analyze\n",
    "    categories = [\n",
    "        \"D Points\",\n",
    "        \"Goals\",\n",
    "        \"Total Assists\",\n",
    "        \"Shots\",\n",
    "        \"Special Teams Points\",\n",
    "        \"Hits\",\n",
    "        \"Shots Blocked\",\n",
    "        \"Takeaways\",\n",
    "        \"Faceoffs Won\",\n",
    "        \"TOI\",\n",
    "    ]\n",
    "\n",
    "    # Calculate z-scores for overall season statistics\n",
    "    # Z-scores standardize data to have mean of 0 and standard deviation of 1\n",
    "    for category in categories:\n",
    "        dataframe[category] = pd.to_numeric(dataframe[category], errors=\"coerce\")\n",
    "    filtered_data = dataframe[categories].apply(zscore)\n",
    "    dataframe[\"Season Value\"] = filtered_data.sum(axis=1)\n",
    "    season_rankings = dataframe.sort_values(\"Season Value\", ascending=False)\n",
    "\n",
    "    # Normalize stats by games played\n",
    "    # This gives per game statistics instead of total season statistics\n",
    "    for category in categories:\n",
    "        dataframe[category] = dataframe[category] / dataframe[\"GP\"]\n",
    "\n",
    "    # Calculate z-scores for per game statistics\n",
    "    filtered_data = dataframe[categories].apply(zscore)\n",
    "    dataframe[\"Per Game Value\"] = filtered_data.sum(axis=1)\n",
    "    per_game_rankings = dataframe.sort_values(\"Per Game Value\", ascending=False)\n",
    "\n",
    "    # Select and order columns\n",
    "    # This makes the data easier to read and understand\n",
    "    season_rankings = season_rankings.loc[:, [\"Season Value\", *COLUMN_ORDER]]\n",
    "    per_game_rankings = per_game_rankings.loc[:, [\"Per Game Value\", *COLUMN_ORDER]]\n",
    "\n",
    "    # Add 'Rank' Column\n",
    "    # This gives a ranking to each player based on their season or per game value\n",
    "    season_rankings.insert(0, \"Rank\", range(1, len(season_rankings) + 1))\n",
    "    per_game_rankings.insert(0, \"Rank\", range(1, len(season_rankings) + 1))\n",
    "\n",
    "    # Return the rankings for both season and per game statistics\n",
    "    return season_rankings, per_game_rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value(season_rankings, per_game_rankings):\n",
    "    gp_min = 5\n",
    "    # Ensure Player and UID is set as index for both dataframes\n",
    "    season_rankings = season_rankings.set_index(\"Player\")\n",
    "    per_game_rankings = per_game_rankings.set_index(\"Player\")\n",
    "    # Filter out players who have played 5 games or less\n",
    "    season_rankings = season_rankings[season_rankings[\"GP\"] > gp_min]\n",
    "    per_game_rankings = per_game_rankings[per_game_rankings[\"GP\"] > gp_min]\n",
    "    # Calculate discrepancy in value\n",
    "    discrepancy = (per_game_rankings[\"Per Game Value\"] - season_rankings[\"Season Value\"])\n",
    "    # Create a new DataFrame for discrepancy\n",
    "    discrepancy_df = discrepancy.to_frame(name=\"Discrepancy\")\n",
    "    # Filter players where Per Game Value is higher than Season Value\n",
    "    filtered_discrepancy = discrepancy_df[discrepancy_df[\"Discrepancy\"] > 0]\n",
    "    # sort player by discrepancy\n",
    "    sorted_discrepancy = filtered_discrepancy.sort_values(\"Discrepancy\", ascending=False)\n",
    "    # Select and return the top 50 players\n",
    "    return sorted_discrepancy.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and print dataframe\n",
    "def format_and_print(dataframe):\n",
    "    # Nested function to color rows\n",
    "    # This function is used to apply a style to the DataFrame\n",
    "    def color_rows(s):\n",
    "        # Use a list comprehension to create a list of styles\n",
    "        # If the row index is even, the background color will be #44475a\n",
    "        # If the row index is odd, the background color will be #282a36\n",
    "        return [\"background-color: #44475a\" if i % 2 else \"background-color: #282a36\" for i in range(len(s))]\n",
    "\n",
    "    # Apply the color_rows function to the DataFrame\n",
    "    # This will color the rows according to the rules defined in color_rows\n",
    "    # The hide method is used to hide the index of the DataFrame\n",
    "    return dataframe.style.apply(color_rows).hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rankings\n",
    "def visualize_top_50_discrepancy(season_rankings, per_game_rankings):\n",
    "    # Get top 50 players by discrepancy\n",
    "    # The find_value function is expected to return a DataFrame of the top 50 players by discrepancy\n",
    "    top_50_players = find_value(season_rankings, per_game_rankings)\n",
    "\n",
    "    # Sort players by discrepancy in ascending order\n",
    "    # This makes it easier to see which players have the largest discrepancy\n",
    "    top_50_players = top_50_players.sort_values(by=\"Discrepancy\", ascending=True)\n",
    "\n",
    "    # Create horizontal bar plot\n",
    "    # The figure size is set to 10x10 for better visibility\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # The y-values are the player names (index of top_50_players)\n",
    "    # The x-values are the discrepancy values\n",
    "    bars = plt.barh(top_50_players.index, top_50_players[\"Discrepancy\"])\n",
    "\n",
    "    # Add discrepancy values at the end of each bar\n",
    "    # This makes it easier to see the exact discrepancy value for each player\n",
    "    for bar in bars:\n",
    "        xval = bar.get_width()\n",
    "        # The text is positioned at the end of the bar, in the middle vertically\n",
    "        plt.text(xval, bar.get_y() + bar.get_height() / 2, round(xval, 2), va=\"center\")\n",
    "\n",
    "    # Set the title of the plot and the labels of the x and y axes\n",
    "    plt.title(\"Top 50 Players by Discrepancy\")\n",
    "    plt.xlabel(\"Discrepancy\")\n",
    "    plt.ylabel(\"Player\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to Google Sheets\n",
    "def output_to_gsheets(dataframe, worksheet_name, column_order):\n",
    "    gc = gspread.oauth()\n",
    "    sh = gc.open(\"FantasyStats\")\n",
    "\n",
    "    # Get the worksheet or create it if it doesn't exist\n",
    "    try:\n",
    "        worksheet = sh.worksheet(worksheet_name)\n",
    "    except gspread.exceptions.WorksheetNotFound:\n",
    "        worksheet = sh.add_worksheet(title=worksheet_name, rows=\"400\", cols=\"25\")\n",
    "\n",
    "    # Clear the worksheet\n",
    "    worksheet.clear()\n",
    "    # Convert the index to a column\n",
    "    dataframe = dataframe.reset_index(level=0)\n",
    "\n",
    "    # Reorder the columns\n",
    "    dataframe = dataframe.reindex(columns=column_order)\n",
    "\n",
    "    # Calculate the range\n",
    "    num_rows = len(dataframe.index) + 1  # +1 to account for the header row\n",
    "    num_cols = len(dataframe.columns)\n",
    "    # Convert column number to letter\n",
    "    col_letter = chr(64 + num_cols)\n",
    "    range_name = f\"A1:{col_letter}{num_rows}\"\n",
    "\n",
    "    # Update the worksheet with the DataFrame data\n",
    "    worksheet.update(values = [dataframe.columns.to_numpy().tolist(),\n",
    "                             *dataframe.to_numpy().tolist()], range_name=range_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    all_strengths = load_data(\"all_strengths.csv\")\n",
    "    even_strength = load_data(\"even_strength.csv\")\n",
    "    all_stats_df = add_d_and_stp(all_strengths, even_strength)\n",
    "    fantrax_data = scrape_fantrax(\"fantrax_data.csv\")  # noqa: F841\n",
    "    season_rankings, per_game_rankings = analyze_data(all_stats_df)\n",
    "    visualize_top_50_discrepancy(season_rankings, per_game_rankings)\n",
    "    output_to_gsheets(season_rankings, \"Season Rankings\", [\"Rank\", \"Season Value\", *COLUMN_ORDER])\n",
    "    output_to_gsheets(per_game_rankings, \"Per Game Rankings\", [\"Rank\", \"Per Game Value\", *COLUMN_ORDER])\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
